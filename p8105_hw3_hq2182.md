p8105\_hw3\_hq2182
================
Hanfei Qi
10/6/2020

Load libraries and do some figure setting.

# Problem 1

Input the data set

``` r
data("instacart")
```

Description:

This data set contains 1384617 rows and 15 columns. Observations are the
level of items in orders by user. There are user / order variables –
user ID, order ID, order day, and order hour. There are also item
variables – name, aisle, department, and some numeric codes such as add
to cart order, reordered, order number, and aisle id.

  - How many aisles, and which are more items from?

<!-- end list -->

``` r
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ... with 124 more rows

Comment: There are 134 aisles, the top three aisles with more items are
“fresh vegetables”, “fresh fruits”, and “packaged vegetables fruits”.
It looks like there are many types of vegetables and fruits.

  - Make a plot that shows the number of items ordered in each aisle,
    limiting this to aisles with more than 10000 items ordered. Arrange
    aisles sensibly, and organize your plot so others can read it.

<!-- end list -->

``` r
instacart %>%
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  labs(
    title = "Number of Items in Each Aisle",
    x = "Name of Aisle",
    y = "Number of Items") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

![](p8105_hw3_hq2182_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

Comment: As I expected, vegetables, fruits, and yogurt have the most
items, and the remaining aisles (\#items \> 10 thousands) have similar
numbers of items.

  - Make a tableMake a table showing the three most popular items in
    each of the aisles “baking ingredients”, “dog food care”, and
    “packaged vegetables fruits”.

<!-- end list -->

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

Comment: It looks like baking requires lots of sugar. Dogs prefer
chicken & rice. People tend to purchase organic fruits.

  - Make a table showing the mean hour of the day at which Pink Lady
    Apples and Coffee Ice Cream are ordered on each day of the week

<!-- end list -->

``` r
instacart %>% 
    filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
    group_by(product_name, order_dow) %>% 
    summarize(mean_hour = mean(order_hour_of_day)) %>% 
  mutate(
    order_dow = recode(
      order_dow,
      `0` = "Sun", `1` = "Mon", `2` = "Tues", `3` = "Wed", `4` = "Thur", `5` = "Fri", `6` = "Sat"
    )
  ) %>% 
    pivot_wider(
        names_from = order_dow,
        values_from = mean_hour
    )
```

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       Sun   Mon  Tues   Wed  Thur   Fri   Sat
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

Comment: Most of time the coffee ice cream is sold in the afternoon,
maybe it’s because the temperature is warmer in the afternoon. Pink lady
apples is sold in the noon, maybe people buy it for lunch.

# Problem 2

  - Load, tidy, and otherwise wrangle the data.

<!-- end list -->

``` r
accel_df = 
  read_csv(
    file = "./accel_data.csv",
    col_names = TRUE) %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    values_to = "activity_number"
  ) %>% 
  mutate(
    day_id = as.factor(day_id),
    week = as.factor(week),
    weekday = case_when(
      day == "Monday" ~ "yes",
      day == "Tuesday" ~ "yes",
      day == "Wednesday" ~ "yes",
      day == "Thurday" ~ "yes",
      day == "Friday" ~ "yes",
      TRUE            ~ "no"),
    weekend = case_when(
      day == "Saturday" ~ "yes",
      day == "Sunday" ~ "yes",
      TRUE           ~ "no"
    ))
```

Description: This data set contains 50400 rows and 7 columns.

  - The following are variables in this data set:
      - week: The number of week since the experiment started
      - day\_id: Unique id of certain day, the number is number of day
        after starting experiment
      - day: Name of weekday
      - activity\_\*: Names of activities, but do not know what is the
        specific activity
      - activity\_number: Counts of each activity
      - weekday: “yes” if the date is weekday, “no” if the date is
        weekend
      - weekend: “yes” if the date is weekend, “no” if the date is
        weekday
  - Add variable of total activity for each day, then make a table

<!-- end list -->

``` r
accel_df %>% 
  group_by(day_id, day) %>% 
  summarize(
    sum_act = sum(activity_number)
  ) %>% 
  arrange(
    desc(sum_act)
  ) %>% 
  knitr::kable()
```

| day\_id | day       |  sum\_act |
| :------ | :-------- | --------: |
| 16      | Monday    | 685910.00 |
| 4       | Sunday    | 631105.00 |
| 29      | Friday    | 620860.00 |
| 10      | Saturday  | 607175.00 |
| 8       | Friday    | 568839.00 |
| 33      | Thursday  | 549658.00 |
| 1       | Friday    | 480542.62 |
| 12      | Thursday  | 474048.00 |
| 21      | Wednesday | 468869.00 |
| 15      | Friday    | 467420.00 |
| 18      | Sunday    | 467052.00 |
| 35      | Wednesday | 445366.00 |
| 14      | Wednesday | 440962.00 |
| 28      | Wednesday | 434460.00 |
| 13      | Tuesday   | 423245.00 |
| 11      | Sunday    | 422018.00 |
| 23      | Monday    | 409450.00 |
| 30      | Monday    | 389080.00 |
| 17      | Saturday  | 382928.00 |
| 20      | Tuesday   | 381507.00 |
| 3       | Saturday  | 376254.00 |
| 19      | Thursday  | 371230.00 |
| 34      | Tuesday   | 367824.00 |
| 5       | Thursday  | 355923.64 |
| 26      | Thursday  | 340291.00 |
| 7       | Wednesday | 340115.01 |
| 27      | Tuesday   | 319568.00 |
| 6       | Tuesday   | 307094.24 |
| 9       | Monday    | 295431.00 |
| 25      | Sunday    | 260617.00 |
| 22      | Friday    | 154049.00 |
| 32      | Sunday    | 138421.00 |
| 2       | Monday    |  78828.07 |
| 24      | Saturday  |   1440.00 |
| 31      | Saturday  |   1440.00 |

Comment:

  - Make a plot shows 24-hour activity time courses for each day
  - Colors indicate day of the week

<!-- end list -->

``` r
accel_df %>% 
  group_by(day_id) %>% 
  ggplot(aes(x = activity, y = activity_number)) +
    geom_point(aes(color = day), alpha = .5) +
  labs(
    title = "24-hour activity time courses for each day",
    x = "Time Line Starting at Midnight",
    y = "Activity Numbers") +
    theme(axis.text.x = element_blank())
```

![](p8105_hw3_hq2182_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

Comment:

# Problem 3

Input and observe the data

``` r
library(patchwork)
library(ggridges)
data("ny_noaa")
summary(ny_noaa)
```

    ##       id                 date                 prcp               snow       
    ##  Length:2595176     Min.   :1981-01-01   Min.   :    0.00   Min.   :  -13   
    ##  Class :character   1st Qu.:1988-11-29   1st Qu.:    0.00   1st Qu.:    0   
    ##  Mode  :character   Median :1997-01-21   Median :    0.00   Median :    0   
    ##                     Mean   :1997-01-01   Mean   :   29.82   Mean   :    5   
    ##                     3rd Qu.:2005-09-01   3rd Qu.:   23.00   3rd Qu.:    0   
    ##                     Max.   :2010-12-31   Max.   :22860.00   Max.   :10160   
    ##                                          NA's   :145838     NA's   :381221  
    ##       snwd            tmax               tmin          
    ##  Min.   :   0.0   Length:2595176     Length:2595176    
    ##  1st Qu.:   0.0   Class :character   Class :character  
    ##  Median :   0.0   Mode  :character   Mode  :character  
    ##  Mean   :  37.3                                        
    ##  3rd Qu.:   0.0                                        
    ##  Max.   :9195.0                                        
    ##  NA's   :591786

Description: This data contains 7 variables: weather station id, date of
observation, precipitation (tenth of mm), snowfall (mm), snow depth
(mm), max/min temperature (tenths of degree C). There are 2595176\` rows
in the data. The amount of NA values in max/min temperature may make
troubles when we want to analyze temp vs. precipitation / snowfall.

  - Separate variables for year, month, and day
  - Ensure units of temperature, precipitation, and snowfall
  - Observe common values for snowfall

<!-- end list -->

``` r
sep_date = ny_noaa %>% 
  separate(col = date, 
           into = c("year", "month", "day")) %>% 
  mutate(
   prcp = prcp / 10,
   tmax_num = as.numeric(tmax) / 10,
   tmin_num = as.numeric(tmin) / 10
  ) 

summary(sep_date$snow) 
```

    ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
    ##     -13       0       0       5       0   10160  381221

``` r
getmode = function(v) {
   uniqv = unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
getmode(sep_date$snow)
```

    ## [1] 0

Comment:

  - Make a two-panel plot showing the average max temperature in January
    and in July in each station across years.

<!-- end list -->

``` r
jun_df = sep_date %>% 
  group_by(id, month, year) %>% 
  summarize(mean_tmax = mean(tmax_num)) %>% 
  filter(month == "06") %>% 
  drop_na()
```

    ## `summarise()` regrouping output by 'id', 'month' (override with `.groups` argument)

``` r
jul_df = sep_date %>% 
  group_by(id, month, year) %>% 
  summarize(mean_tmax = mean(tmax_num)) %>% 
  filter(month == "07") %>% 
  drop_na()
```

    ## `summarise()` regrouping output by 'id', 'month' (override with `.groups` argument)

``` r
jun_p = 
  jun_df %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id)) +
  geom_line(alpha = .5) +
  geom_path() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

jul_p = 
  jul_df %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id)) +
  geom_line(alpha = .5) +
  geom_path() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

jun_p / jul_p
```

![](p8105_hw3_hq2182_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->

Comment:

  - Make a two-panel plot: tmax vs tmin for the full dataset.
  - Make a plot: the distribution of snowfall values greater than 0 and
    less than 100 separately by year.

<!-- end list -->

``` r
tmax_tmin_p = 
  sep_date %>% 
  drop_na() %>% 
  ggplot(aes(x = tmin_num, y = tmax_num)) +
  geom_hex() +
  labs(
    title = "tmax vs. tmin for the full dataset",
    x = "Minimum Temperature",
    y = "Maximum Temperature")
```

``` r
distr_snow_p = 
  sep_date %>% 
  filter(snow > 0 &
           snow < 100) %>% 
  drop_na(snow) %>% 
  ggplot(
    aes(x = year, y = snow)
    ) +
  geom_violin(aes(fill = year), alpha = .5) +
  stat_summary(fun = "median", color = "black") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  theme(legend.position = "bottom",
        legend.text = element_text(size = 7),
        legend.key.size = unit(0.5, "lines"))

tmax_tmin_p / distr_snow_p
```

![](p8105_hw3_hq2182_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->

Comment:
